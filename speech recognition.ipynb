{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "from scipy.io import wavfile\n",
    "from python_speech_features import mfcc\n",
    "import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tft\n",
    "tft.compat.v1.disable_eager_execution()\n",
    "import os\n",
    "import re\n",
    "from tensorflow.python import ops\n",
    "import time\n",
    "\n",
    "chars = \"abcdefghijklmnopqrstuvwxyz' \"\n",
    "n_inp=26\n",
    "n_ctx = 9\n",
    "n_h = 1024\n",
    "n_chars = len(chars)+1\n",
    "pb1 = 0.9\n",
    "pb2 = 0.999\n",
    "peps = 1e-8\n",
    "plr = 0.001\n",
    "epochs=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audiofile_to_vector(audio_fname, n_mfcc_features, nctx):\n",
    "    sampling_rate, raw_w = wavfile.read(audio_fname)\n",
    "    mfcc_ft = mfcc(raw_w, samplerate=sampling_rate, numcep=n_mfcc_features)\n",
    "    mfcc_ft = mfcc_ft[::2]\n",
    "    n_strides = len(mfcc_ft)\n",
    "    dummy_ctx = np.zeros((nctx, n_mfcc_features), dtype=mfcc_ft.dtype)\n",
    "    mfcc_ft = np.concatenate((dummy_ctx, mfcc_ft, dummy_ctx))\n",
    "    w_size = 2*nctx+1\n",
    "    input_vector = np.lib.stride_tricks.as_strided(mfcc_ft,(n_strides, w_size, n_mfcc_features),\n",
    "        (mfcc_ft.strides[0], mfcc_ft.strides[0], mfcc_ft.strides[1]),\n",
    "        writeable=False)\n",
    "    input_vector = np.reshape(input_vector, [n_strides, -1])\n",
    "    input_vector = np.copy(input_vector)\n",
    "    input_vector = (input_vector - np.mean(input_vector))/np.std(input_vector)\n",
    "    return input_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(171, 494)\n"
     ]
    }
   ],
   "source": [
    "mfcc_features = audiofile_to_vector('C://Users//shash//Desktop//speech recognition//timit//dr1-fvmh0//sa1.wav',26,9)\n",
    "print(mfcc_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "regexp_alphabets = \"[^a-zA-Z']+\"\n",
    "cnt=0\n",
    "def get_label(ch):\n",
    "    global cnt\n",
    "    label = cnt\n",
    "    cnt+=1\n",
    "    return label\n",
    "chr2lbl = {c:get_label(c) for c in list(chars)}\n",
    "lbl2chr = {chr2lbl[c]:c for c in list(chars)}\n",
    "def get_string2label(strval):\n",
    "    strval = strval.lower()\n",
    "    idlist = []\n",
    "    for c in list(strval):\n",
    "        if c in chr2lbl:\n",
    "            idlist.append(chr2lbl[c])\n",
    "    return np.array(idlist)\n",
    "def get_label2string(lblarr):\n",
    "    strval = []\n",
    "    for idv in lblarr:\n",
    "        strval.append(lbl2chr[idv])\n",
    "    return ''.join(strval)\n",
    "def decoded_val_to_text(decoded_val):\n",
    "    idxs = decoded_val[0]\n",
    "    vals = decoded_val[1]\n",
    "    res = [''] * decoded_val[2][0]\n",
    "    for i in range(len(idxs)):\n",
    "        idx = idxs[i][0]\n",
    "        char = lbl2chr[vals[i]]\n",
    "        res[idx] = res[idx] + char\n",
    "    return res\n",
    "def array2txt(arr_val):\n",
    "    res = ''\n",
    "    for i in range(len(arr_val)):\n",
    "        if arr_val[i] in lbl2chr:\n",
    "            res += lbl2chr[arr_val[i]]\n",
    "        else:\n",
    "            res += ''\n",
    "    return res.replace('`', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19  7  8 18 27  8 18 27  0 27 19  4 18 19]\n",
      "this is a test\n"
     ]
    }
   ],
   "source": [
    "idlist = get_string2label(\"This is a test\")\n",
    "print(idlist)\n",
    "strval = get_label2string(idlist)\n",
    "print(strval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wav_trans(fpath,X, y):\n",
    "    files = os.listdir(fpath)\n",
    "    for fname in files:\n",
    "        next_path = fpath + \"/\" + fname\n",
    "        if os.path.isdir(next_path):\n",
    "            get_wav_trans(next_path,X,y)\n",
    "        else:\n",
    "            if fname.endswith('wav'):\n",
    "                fname_without_ext = fname.split(\".\")[0]\n",
    "                trans_fname = fname_without_ext + \".txt\"\n",
    "                trans_fname_path = fpath + \"/\" + trans_fname\n",
    "                if os.path.isfile(trans_fname_path):\n",
    "                    mfcc_ft = audiofile_to_vector(next_path,n_inp,n_ctx)\n",
    "                    with open(trans_fname_path,'r') as content:\n",
    "                        transcript = content.read()\n",
    "                        transcript = re.sub(regexp_alphabets, ' ', transcript).strip().lower()\n",
    "                    trans_lbl = get_string2label(transcript)\n",
    "                    X.append(mfcc_ft)\n",
    "                    y.append(trans_lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layers(X_batch,seq_len):\n",
    "    X_batch_shape = tft.shape(X_batch)\n",
    "    X_batch = tft.transpose(X_batch, [1, 0, 2])\n",
    "    X_batch = tft.reshape(X_batch, [-1, n_inp + 2*n_inp*n_ctx])\n",
    "    \n",
    "    with tft.name_scope('Lyr1'):\n",
    "        B1 = tft.get_variable(name='B1', shape=[n_h], \n",
    "                             initializer=tft.random_normal_initializer(stddev=0.046875))\n",
    "        H1 = tft.get_variable(name='H1', shape=[n_inp + 2*n_inp*n_ctx, n_h],\n",
    "                             initializer=tf.contrib.layers.xavier_initializer(uniform=False))\n",
    "        logits1 = tft.add(tf.matmul(X_batch, H1), B1)\n",
    "        relu1 = tft.nn.relu(logits1)\n",
    "        clipped_relu1 = tft.minimum(relu1,20.0)\n",
    "        Lyr1 = tft.nn.dropout(clipped_relu1, 0.5)\n",
    "    with tft.name_scope('Lyr2'):\n",
    "        B2 = tft.get_variable(name='B2', shape=[n_h], \n",
    "                             initializer=tft.random_normal_initializer(stddev=0.046875))\n",
    "        H2 = tft.get_variable(name='H2', shape=[n_h,n_h],\n",
    "                             initializer=tft.random_normal_initializer(stddev=0.046875))\n",
    "        logits2 = tft.add(tft.matmul(Lyr1, H2), B2)\n",
    "        relu2 = tft.nn.relu(logits2)\n",
    "        clipped_relu2 = tft.minimum(relu2,20.0)\n",
    "        Lyr2 = tft.nn.dropout(clipped_relu2, 0.5)\n",
    "    with tf.name_scope('Lyr3'):\n",
    "        B3 = tft.get_variable(name='B3', shape=[2*n_h], \n",
    "                             initializer=tft.random_normal_initializer(stddev=0.046875))\n",
    "        H3 = tft.get_variable(name='H3', shape=[n_h,2*n_h],\n",
    "                             initializer=tft.random_normal_initializer(stddev=0.046875))\n",
    "        logits3 = tft.add(tft.matmul(Lyr2, H3), B3)\n",
    "        relu3 = tft.nn.relu(logits3)\n",
    "        clipped_relu3 = tft.minimum(relu3,20.0)\n",
    "        Lyr3 = tft.nn.dropout(clipped_relu3, 0.5)\n",
    "    \n",
    "    with tf.name_scope('RNN_Lyr'):\n",
    "        fw_c = tft.contrib.rnn.BasicLSTMCell(n_h, forget_bias=1.0, state_is_tuple=True, \n",
    "                                            reuse=tft.get_variable_scope().reuse)\n",
    "        fw_c = tft.contrib.rnn.DropoutWrapper(fw_c, input_keep_prob=0.7, output_keep_prob=0.7,seed=123)\n",
    "        bw_c = tft.contrib.rnn.BasicLSTMCell(n_h, forget_bias=1.0, state_is_tuple=True, \n",
    "                                                    reuse=tft.get_variable_scope().reuse)\n",
    "        bw_c = tft.contrib.rnn.DropoutWrapper(bw_c,input_keep_prob=0.7, output_keep_prob=0.7,\n",
    "                                                    seed=123)\n",
    "        Lyr3 = tft.reshape(Lyr3, [-1, X_batch_shape[0], 2*n_h])\n",
    "        outs, out_states = tf.nn.bidirectional_dynamic_rnn(cell_fw=fw_c,\n",
    "                                                                     cell_bw=bw_c,\n",
    "                                                                     inputs=Lyr3,\n",
    "                                                                     dtype=tf.float32,\n",
    "                                                                     time_major=True,\n",
    "                                                                     sequence_length=seq_len)\n",
    "        outs = tft.concat(outs, 2)\n",
    "        outs = tft.reshape(outs, [-1, 2 * n_h])\n",
    "    \n",
    "    with tft.name_scope('Lyr4'):\n",
    "        B4 = tft.get_variable(name='B4', shape=[n_h], \n",
    "                             initializer=tft.random_normal_initializer(stddev=0.046875))\n",
    "        H4 = tft.get_variable(name='H4', shape=[(2 * n_h), n_h],\n",
    "                             initializer=tft.random_normal_initializer(stddev=0.046875))\n",
    "        logits4 = tft.add(tft.matmul(outs, H4), B4)\n",
    "        relu4 = tft.nn.relu(logits4)\n",
    "        clipped_relu4 = tft.minimum(relu4,20.0)\n",
    "        Lyr4 = tft.nn.dropout(clipped_relu4, 0.5)\n",
    "    \n",
    "    with tft.name_scope('Lyr5'):\n",
    "        B5 = tft.get_variable(name='B5', shape=[n_chars], \n",
    "                             initializer=tft.random_normal_initializer(stddev=0.046875))\n",
    "        H5 = tft.get_variable(name='H5', shape=[n_h, n_chars],\n",
    "                             initializer=tft.random_normal_initializer(stddev=0.046875))\n",
    "        Lyr5 = tft.add(tft.matmul(Lyr4, H5), B5)\n",
    "        Lyr5 = tft.reshape(Lyr5, [-1, X_batch_shape[0], n_chars])\n",
    "    \n",
    "    return Lyr5\n",
    "    \n",
    "\n",
    "def get_logits(X_batch,seq_len):\n",
    "    logits = get_layers(X_batch,seq_len)\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Batch:\n",
    "    def __init__(self):\n",
    "        self.start_idx = 0\n",
    "        self.batch_size = 32\n",
    "        self.audio = []\n",
    "        self.transcript = []\n",
    "        get_wav_trans(\"C://Users//shash//Desktop//speech recognition//timit\",self.audio,self.transcript)     \n",
    "    def pad_seq(self,seqs):\n",
    "        seq_lens = np.asarray([len(st) for st in seqs], dtype=np.int64)\n",
    "        n_s = len(seqs)\n",
    "        max_seq_len = np.max(seq_lens)\n",
    "        s_shape = tuple()\n",
    "        for s in seqs:\n",
    "            if len(s) > 0:\n",
    "                s_shape = np.asarray(s).shape[1:]\n",
    "                break\n",
    "        seqs_trc = (np.ones((n_s, max_seq_len) + s_shape) * 0.).astype(np.float32)\n",
    "        for ix, s in enumerate(seqs):\n",
    "            if len(s) == 0:\n",
    "                continue  \n",
    "            trc = s[:max_seq_len]\n",
    "            trc = np.asarray(trc, dtype=np.int64)\n",
    "            if trc.shape[1:] != s_shape:\n",
    "                raise ValueError(\"ERROR in truncation shape\")\n",
    "            seqs_trc[ix, :len(trc)] = trc\n",
    "        return seqs_trc, seq_lens\n",
    "    def get_sp_tuple(self,seqs):\n",
    "        ixs = []\n",
    "        vals = []\n",
    "        for n, s in enumerate(seqs):\n",
    "            ixs.extend(zip([n] * len(s), range(len(s))))\n",
    "            vals.extend(s)\n",
    "        ixs = np.asarray(ixs, dtype=np.int64)\n",
    "        vals = np.asarray(vals, dtype=np.int32)\n",
    "        shape = np.asarray([len(seqs), ixs.max(0)[1] + 1], dtype=np.int64)\n",
    "        return ixs, vals, shape\n",
    "    def get_next_batch(self):\n",
    "        src = self.audio[self.start_idx:self.start_idx+self.batch_size]\n",
    "        tgt = self.transcript[self.start_idx:self.start_idx+self.batch_size]\n",
    "        self.start_idx += self.batch_size\n",
    "        if(self.start_idx>len(self.audio)):\n",
    "            self.start_idx=0\n",
    "        src,src_len = self.pad_seq(src)\n",
    "        sp_lbls = self.get_sp_tuple(tgt)\n",
    "        return src, src_len, sp_lbls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    input_t = tft.placeholder(tft.float32, [None, None, n_inp + \n",
    "                                                (2 * n_inp * n_ctx)], name='inp')\n",
    "    tgts = tft.sparse_placeholder(tft.int32, name='tgts')\n",
    "    len_seq = tft.placeholder(tft.int32, [None], name='len_seq')\n",
    "    logits = get_logits(input_t,tft.to_int64(len_seq))\n",
    "    return input_t, tgts, len_seq, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cost(tgts,logits,len_seq):\n",
    "    loss_t = ops.ctc_ops.ctc_loss(tgts, logits, len_seq)\n",
    "    loss_avg = tf.reduce_mean(loss_t)\n",
    "    return loss_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(logits,len_seq,loss_avg):\n",
    "    adm_opt = tf.train.AdamOptimizer(learning_rate=plr,beta1=pb1,beta2=pb2,epsilon=peps)\n",
    "    adm_opt = adm_opt.minimize(loss_avg)\n",
    "    dec, prob_log = ops.ctc_ops.ctc_beam_search_decoder(logits, len_seq, merge_repeated=False)\n",
    "    return adm_opt,dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_error_rates(dec,tgts):\n",
    "    edit_dist = tf.edit_distance(tf.cast(dec[0], tf.int32), tgts)\n",
    "    error_rate4label = tf.reduce_mean(edit_dist, name='error_rate4label')\n",
    "    return error_rate4label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'contrib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-53195b76d302>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0minput_t\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtgts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen_seq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mloss_avg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_cost\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtgts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen_seq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0madm_opt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_optimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen_seq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss_avg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-53-f8ad7e38c0a1>\u001b[0m in \u001b[0;36mget_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mtgts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse_placeholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'tgts'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mlen_seq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'len_seq'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_logits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_t\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_int64\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen_seq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minput_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtgts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen_seq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-51-557890de259a>\u001b[0m in \u001b[0;36mget_logits\u001b[1;34m(X_batch, seq_len)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_logits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m     \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_layers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mlogits\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-51-557890de259a>\u001b[0m in \u001b[0;36mget_layers\u001b[1;34m(X_batch, seq_len)\u001b[0m\n\u001b[0;32m      8\u001b[0m                              initializer=tft.random_normal_initializer(stddev=0.046875))\n\u001b[0;32m      9\u001b[0m         H1 = tft.get_variable(name='H1', shape=[n_inp + 2*n_inp*n_ctx, n_h],\n\u001b[1;32m---> 10\u001b[1;33m                              initializer=tf.contrib.layers.xavier_initializer(uniform=False))\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mlogits1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mH1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mB1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mrelu1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'contrib'"
     ]
    }
   ],
   "source": [
    "gr = tf.Graph()\n",
    "with gr.as_default():\n",
    "    input_t,tgts,len_seq,logits = get_model()\n",
    "    loss_avg = get_cost(tgts,logits,len_seq)\n",
    "    adm_opt, dec = get_optimizer(logits,len_seq,loss_avg)\n",
    "    error_rate = get_error_rates(dec,tgts)\n",
    "    sess = tf.Session()\n",
    "    writer = tf.summary.FileWriter('/tmp/models/', graph=sess.graph)\n",
    "    loss_summary = tf.summary.scalar(\"loss_avg\", loss_avg)\n",
    "    sum_op = tf.summary.merge_all()\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    for ep in range(epochs):\n",
    "        train_cost = 0\n",
    "        label_err_rate = 0\n",
    "        batch_feeder = Batch()\n",
    "        n_batches = np.ceil(len(batch_feeder.audio)/batch_feeder.batch_size)\n",
    "        n_batches = int(n_batches)\n",
    "        st = time.time()\n",
    "        for batch in range(n_batches):\n",
    "            src,len_src,labels_src = batch_feeder.get_next_batch()\n",
    "            data_dict = {input_t: src, tgts: labels_src,len_seq:len_src}\n",
    "            batch_cost, _,summ = sess.run([loss_avg, adm_opt,sum_op], data_dict)\n",
    "            train_cost += batch_cost * batch_feeder.batch_size\n",
    "            print(\"Batch cost: {0}, Train cost: {1}\".format(batch_cost,train_cost))\n",
    "            label_err_rate += sess.run(error_rate, feed_dict=data_dict) * batch_feeder.batch_size\n",
    "            print('Label error: {}'.format(label_err_rate))\n",
    "            writer.add_summary(summ,ep*batch_feeder.batch_size+batch)\n",
    "        saver = tf.train.Saver() \n",
    "        saver.save(sess, '/tmp/models/speech2txt.ckpt')\n",
    "        decoded_val = sess.run(dec[0], feed_dict=data_dict)\n",
    "        d_decoded_val = tf.sparse_tensor_to_dense(decoded_val, default_value=-1).eval(session=sess)\n",
    "        d_lbl = decoded_val_to_text(labels_src)\n",
    "        cnt = 0\n",
    "        cnt_max = 4\n",
    "        if cnt < cnt_max:\n",
    "            for actual_val, decoded_val in zip(d_lbl, d_decoded_val):\n",
    "                d_str = array2txt(decoded_val)\n",
    "                print('Batch {}'.format(batch))\n",
    "                print('Actual: {}'.format(actual_val))\n",
    "                print('Predicted:  {}'.format(d_str))\n",
    "                cnt += 1\n",
    "        time_taken = time.time() - st\n",
    "        log = 'Epoch {}/{}, training_cost: {:.3f}, error_rate: {:.3f}, time: {:.2f} sec'\n",
    "        print(log.format(ep,epochs,train_cost/len(batch_feeder.audio),\n",
    "                (label_err_rate/len(batch_feeder.audio)), time_taken))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
